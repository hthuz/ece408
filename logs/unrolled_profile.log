**** collection configuration ****
	force-overwrite = false
	stop-on-exit = true
	export_sqlite = true
	stats = true
	capture-range = none
	stop-on-range-end = false
	Beta: ftrace events:
	ftrace-keep-user-config = false
	trace-GPU-context-switch = false
	delay = 0 seconds
	duration = 0 seconds
	kill = signal number 15
	inherit-environment = true
	show-output = true
	trace-fork-before-exec = false
	sample_cpu = true
	backtrace_method = LBR
	wait = all
	trace_cublas = false
	trace_cuda = true
	trace_cudnn = false
	trace_nvtx = true
	trace_mpi = false
	trace_openacc = false
	trace_vulkan = false
	trace_opengl = true
	trace_osrt = true
	osrt-threshold = 0 nanoseconds
	cudabacktrace = false
	cudabacktrace-threshold = 0 nanoseconds
	profile_processes = tree
	application command = ./m3
	application arguments = 
	application working directory = /build
	NVTX profiler range trigger = 
	NVTX profiler domain trigger = 
	environment variables:
	Collecting data...
Running test case 1
B = 1 M = 3 C = 3 H = 224 W = 224 K = 3 S = 1
Running test case 2
B = 2 M = 3 C = 3 H = 301 W = 301 K = 3 S = 2
Running test case 3
B = 3 M = 3 C = 3 H = 196 W = 196 K = 3 S = 3
Running test case 4
B = 4 M = 3 C = 3 H = 239 W = 239 K = 3 S = 4
All test cases passed
Test batch size: 5000
Loading fashion-mnist data...Done
Loading model...Done
Conv-GPU==
Layer Time: 384.358 ms
Op Time: 47.5289 ms
Conv-GPU==
Layer Time: 291.319 ms
Op Time: 45.2846 ms

Test Accuracy: 0.871

	Generating the /build/report1.qdstrm file.
	Capturing raw events...
	335212 total events collected.
	Capturing symbol files...
	Saving diagnostics...
	Saving qdstrm file to disk...
	Finished saving file.


Importing the qdstrm file using /opt/nvidia/nsight-systems/2019.5.2/host-linux-x64/QdstrmImporter.

Importing...

Importing [==================================================100%]
Saving report to file "/build/report1.qdrep"
Report file saved.
Please discard the qdstrm file and use the qdrep file instead.

Removed /build/report1.qdstrm as it was successfully imported.
Please use the qdrep file instead.

Exporting the qdrep file to SQLite database using /opt/nvidia/nsight-systems/2019.5.2/host-linux-x64/nsys-exporter.

Exporting 335041 events:

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************

Exported successfully to
/build/report1.sqlite

Generating CUDA API Statistics...
CUDA API Statistics (nanoseconds)

Time(%)      Total Time       Calls         Average         Minimum         Maximum  Name                                                                            
-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------
   45.3       579167944          20      28958397.2           29262       310707014  cudaMemcpy                                                                      
   29.7       379362490          26      14590865.0            3291       187403722  cudaMalloc                                                                      
   23.4       298456950          26      11479113.5            2909        75239963  cudaFree                                                                        
    1.6        20838644          16       1302415.2            6246        20484253  cudaLaunchKernel                                                                
    0.0           61530          10          6153.0            3525           16327  cudaDeviceSynchronize                                                           




Generating CUDA Kernel Statistics...

Generating CUDA Memory Operation Statistics...
CUDA Kernel Statistics (nanoseconds)

Time(%)      Total Time   Instances         Average         Minimum         Maximum  Name                                                                            
-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------
   61.5        47021496           6       7836916.0            5664        24587482  unroll_input_kernel                                                             
   38.5        29424459           6       4904076.5            6048        15644946  conv_forward_kernel_multiply                                                    
    0.0            2752           2          1376.0            1376            1376  do_not_remove_this_kernel                                                       
    0.0            2559           2          1279.5            1279            1280  prefn_marker_kernel                                                             


CUDA Memory Operation Statistics (nanoseconds)

Time(%)      Total Time  Operations         Average         Minimum         Maximum  Name                                                                            
-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------
   92.9       531245175           6      88540862.5           13152       309907887  [CUDA memcpy DtoH]                                                              
    7.1        40360364          14       2882883.1            1152        20690980  [CUDA memcpy HtoD]                                                              


CUDA Memory Operation Statistics (KiB)

            Total      Operations            Average            Minimum            Maximum  Name                                                                            
-----------------  --------------  -----------------  -----------------  -----------------  --------------------------------------------------------------------------------
         862672.0               6           143778.7            148.535           500000.0  [CUDA memcpy DtoH]                                                              
         276206.0              14            19729.0              0.004           144453.0  [CUDA memcpy HtoD]                                                              




Generating Operating System Runtime API Statistics...
Operating System Runtime API Statistics (nanoseconds)

Time(%)      Total Time       Calls         Average         Minimum         Maximum  Name                                                                            
-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------
   33.2     52324645676         538      97257705.7           16902       100352136  sem_timedwait                                                                   
   33.2     52290338603         537      97374932.2           24994       100465505  poll                                                                            
   22.2     35008713379          70     500124476.8       500051270       500185461  pthread_cond_timedwait                                                          
   11.0     17288623514           2    8644311757.0      4358424540     12930198974  pthread_cond_wait                                                               
    0.3       507476975         966        525338.5            1019        65199826  ioctl                                                                           
    0.0        22154085        9420          2351.8            1031           18993  read                                                                            
    0.0         3239458         100         32394.6            1163         1246015  mmap                                                                            
    0.0         1228303         101         12161.4            4157           24438  open64                                                                          
    0.0          473945          19         24944.5            3919          102048  fopen64                                                                         
    0.0          292607           5         58521.4           39267           69513  pthread_create                                                                  
    0.0          230668          26          8871.8            1025          156201  fopen                                                                           
    0.0          137812           3         45937.3           41847           52225  fgets                                                                           
    0.0          125386          18          6965.9            1189           16038  fflush                                                                          
    0.0          115409          23          5017.8            1503           15264  munmap                                                                          
    0.0           90211          25          3608.4            1079           11135  fclose                                                                          
    0.0           65115          15          4341.0            1691            6612  write                                                                           
    0.0           30148           5          6029.6            4179            7856  open                                                                            
    0.0           22765           2         11382.5            5308           17457  socket                                                                          
    0.0           12049           2          6024.5            4350            7699  pthread_cond_signal                                                             
    0.0           11725           6          1954.2            1078            5344  fwrite                                                                          
    0.0            9502           8          1187.8            1021            1377  fcntl                                                                           
    0.0            7695           1          7695.0            7695            7695  pipe2                                                                           
    0.0            7201           1          7201.0            7201            7201  connect                                                                         
    0.0            1586           1          1586.0            1586            1586  bind                                                                            
    0.0            1315           1          1315.0            1315            1315  listen                                                                          



